{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triple file consists of URI (Unique Resource Index) like a webpage link, In the first step, we are cleaning the triple file by removing these URI reference in the entities and predicates.\n",
    "\n",
    "sample format is - <http://rdf.freebase.com/ns/g.11vjz1ynm> <http://rdf.freebase.com/ns/measurement_unit.dated_percentage.date> \"2001-02\"\n",
    "\n",
    "In this step, We are removing the URI reference and making it look like, <g.11vjz1ynm> <measurement_unit.dated_percentage.date> \"2001-02\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading freebase_data.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import io\n",
    "tripleFileNames = ['freebase_data.txt']\n",
    "pred_type = \"type>\"\n",
    "rdf_property = \"rdf\"\n",
    "sep = \"####\"\n",
    "tripleFile = io.open('triplefiles_basic.txt','w+',encoding='utf-8')\n",
    "for fname in tripleFileNames:\n",
    "    file = io.open('./'+fname,encoding='utf-8')\n",
    "    print('reading '+fname)\n",
    "    i = 0\n",
    "    for record in file:\n",
    "        i += 1\n",
    "        if record[0] != '<':\n",
    "            continue\n",
    "        record = re.split(r'\\t+', record)\n",
    "        triple=list()\n",
    "        if pred_type in record[1]:\n",
    "            if rdf_property not in record[1]:\n",
    "                continue\n",
    "        for index,word in enumerate(record):\n",
    "            if not word:\n",
    "                break  \n",
    "            if word.startswith(\"<\"):\n",
    "                fpath = word.rfind(\"/\")\n",
    "                pred = word[fpath+1:-1].split(\"#\")\n",
    "                if len(pred)<2:\n",
    "                    triple.append(\"<\"+pred[0]+\">\")\n",
    "                else:\n",
    "                    triple.append('<'+pred[1]+'>')\n",
    "            elif word.count('\"') >=2:\n",
    "                word = word.split('^^')[0].split('@')[0]\n",
    "                procWord = '\"'+''.join(re.findall('\"(.*)\"',word))+'\"'\n",
    "                triple.append(procWord)\n",
    "                continue\n",
    "        tripleFile.write('\\t'.join(triple)+'\\n')\n",
    "    file.close()\n",
    "tripleFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the preprocessed triples file - \n",
    "\n",
    "We extracted ***subject, predicate and object pairs*** to sub_pred_obj_triples.txt and sub_pred_obj_triples1.txt files\n",
    "\n",
    "***Predicate domain and range*** values into predicate_domain_range.txt and predicate_domain_range1.txt files\n",
    "\n",
    "***Entities*** and its names into objectNames.txt anf objectNames1.txt files\n",
    "\n",
    "***Unique Predicates*** into Unique_predicates.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objNames = open('objectNames.txt','a+',encoding='utf-8')\n",
    "tripleFile = open('sub_pred_obj_triples.txt','a+',encoding='utf-8')\n",
    "domainRange = open('predicate_domain_range.txt','a+',encoding='utf-8')\n",
    "uniquePred = open('unique_predicates.txt','a+',encoding='utf-8')\n",
    "nametags = [\"<type.object.name>\",\"<label>\"]\n",
    "domrangetags = [\"<domain>\",\"<range>\"]\n",
    "with open('triplefiles_basic.txt','r',encoding='utf-8') as file:\n",
    "    for record in file:\n",
    "        record = re.split(r'\\t+', record)\n",
    "        if record[0].startswith(\"<m.\") and record[2].startswith(\"<m.\"):\n",
    "            tripleFile.write('\\t'.join(record)+'\\n')\n",
    "        elif record[1] in nametags:\n",
    "            objNames.write('\\t'.join(record)+'\\n')\n",
    "        elif record[1] in domrangetags:\n",
    "            domainRange.write('\\t'.join(record)+'\\n')\n",
    "        elif record[1] == \"<unique>\" and record[2] == \"true\":\n",
    "            uniquePred.write(record[0])\n",
    "objNames.close()\n",
    "tripleFile.close()\n",
    "domainRange.close()\n",
    "uniquePred.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objNames = open('objectNames1.txt','a+',encoding='utf-8')\n",
    "tripleFile = open('sub_pred_obj_triples1.txt','a+',encoding='utf-8')\n",
    "domainRange = open('predicate_domain_range1.txt','a+',encoding='utf-8')\n",
    "uniquePred = open('unique_predicates.txt','a+',encoding='utf-8')\n",
    "nametags = [\"<type.object.name>\",\"<label>\"]\n",
    "domrangetags = [\"<domain>\",\"<range>\"]\n",
    "with open('triplefiles_basic.txt','r',encoding='utf-8') as file:\n",
    "    for record in file:\n",
    "        record = re.split(r'\\t+', record)\n",
    "        if record[0].startswith(\"<m.\") and record[2].startswith(\"<m.\"):\n",
    "            tripleFile.write('\\t'.join(record)+'\\n')\n",
    "        elif record[1] in nametags:\n",
    "            objNames.write('\\t'.join(record)+'\\n')\n",
    "        elif record[1] in domrangetags:\n",
    "            domainRange.write('\\t'.join(record)+'\\n')\n",
    "        elif record[1] == \"<unique>\" and record[2] == \"true\":\n",
    "            uniquePred.write(record[0])\n",
    "objNames.close()\n",
    "tripleFile.close()\n",
    "domainRange.close()\n",
    "uniquePred.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
